{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- encoding:utf-8 -*-\n",
    "import pandas as pd\n",
    "import base64\n",
    "import urllib.parse\n",
    "import re\n",
    "import nltk\n",
    "import urllib\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_number(str):\n",
    "    try:\n",
    "        float(str)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def is_letter(str):\n",
    "    return str.isalpha() and len(str) <=2\n",
    "\n",
    "def is_base64_code(str):\n",
    "    if len(str) < 20 :\n",
    "        return False\n",
    "    return  re.match('^[a-zA-Z0-9+-/=_]*[a-zA-Z0-9+-/=_]$', str)# re.match('[a-zA-Z0-9+/=]', str)\n",
    "\n",
    "def is_base64_code_ex(str):\n",
    "    if len(str) < 20:\n",
    "        return False\n",
    "    return  re.match('^[a-zA-Z0-9+-/=_ ]*[a-zA-Z0-9+-/=_ ]$', str)\n",
    "\n",
    "def base64_url_decode(inp):\n",
    "    # 通过url传输时去掉了=号，所以需要补上=号\n",
    "    if len(inp) % 4 != 0:\n",
    "        try:\n",
    "            return base64.urlsafe_b64decode(str(inp)+'='* (4 - len(inp) % 4))\n",
    "        except:\n",
    "            return inp\n",
    "    else:\n",
    "        try:\n",
    "            return base64.urlsafe_b64decode(str(inp))\n",
    "        except:\n",
    "            return inp\n",
    "\n",
    "def base64_url_encode(inp):\n",
    "    return base64.urlsafe_b64encode(str(inp)).rstrip('=')\n",
    "\n",
    "def to_bytestring(s, enc='utf-8'):\n",
    "    if s:\n",
    "        if isinstance(s, str):\n",
    "            return s\n",
    "        else :\n",
    "            return s.encode(enc)\n",
    "\n",
    "def decode_file(file_name):\n",
    "    names = ['no', 'flag', 'url', 'action']\n",
    "    df = pd.read_csv(file_name, sep = ',', encoding = 'utf-8', names=names)\n",
    "    params_list = []\n",
    "    for no, flag, action in zip(df['no'], df['flag'], df['action']):\n",
    "        new_params = []\n",
    "        if type(action) is float:\n",
    "            #print (no, 'dddd')\n",
    "            action=str(action)\n",
    "            params_list.append(action)\n",
    "            continue\n",
    "        rs = urllib.parse.urlparse('http://xxx?'+action)\n",
    "\n",
    "        query_set = urllib.parse.parse_qs(rs.query)\n",
    "        if len(query_set) == 0:\n",
    "            #print action\n",
    "            new_params.append(action)\n",
    "            params_list.append(new_params)\n",
    "            continue\n",
    "        for key, value in query_set.items():\n",
    "            param = ''.join(value)\n",
    "\n",
    "            if is_base64_code(param):\n",
    "                new_param = base64_url_decode(param)\n",
    "            else:\n",
    "                new_param = ''\n",
    "                if is_base64_code_ex(param) :\n",
    "                    try:\n",
    "                        for part_param in param.split(' '):\n",
    "                            try:\n",
    "                                temp = base64_url_decode(part_param)\n",
    "                                new_param += str(temp)\n",
    "                            except:\n",
    "                                new_param += part_param\n",
    "                    except:\n",
    "                        new_param = param\n",
    "                else :\n",
    "                    new_param = param\n",
    "\n",
    "            new_params.append(new_param)\n",
    "            query_set[key] = new_param.split()\n",
    "        params_list.append(new_params)\n",
    "        flag_list=[]\n",
    "        for item in df['flag']:\n",
    "            if item==\"w\":\n",
    "                flag_list.append(1)\n",
    "            else:\n",
    "                flag_list.append(0)\n",
    "    return params_list,flag_list\n",
    "def cut_word(params_list):\n",
    "    doc_word_list = []\n",
    "    for params in params_list:\n",
    "        param_word_list = list()\n",
    "        text = nltk.word_tokenize(str(params))\n",
    "        for w in text:\n",
    "            w = w.lower().lstrip(' ').rstrip(' ').replace(\"u'\", ' ')\n",
    "            if w[0] == \"'\":\n",
    "                w = w[1:]\n",
    "            w = w.lstrip(' ').rstrip(' ')\n",
    "            w=w.lstrip('[').rstrip(']')\n",
    "            if (is_number(w) == False and len(w) < 50 and is_letter(w) == False and len(w) != 0):\n",
    "                param_word_list.append(w)\n",
    "        doc_word_list.append(param_word_list)\n",
    "\n",
    "    return doc_word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmp(word_list,feature):\n",
    "    cnt=0\n",
    "    for word in word_list:\n",
    "        if word in feature:\n",
    "            cnt=cnt+1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_doc_features_matrix(doc_word_list, features):\n",
    "    rows = len(doc_word_list)\n",
    "    cols = len(features)\n",
    "    doc_features_matrix = np.zeros((rows, cols))\n",
    "    for i in range(1, rows):\n",
    "        for j in range(1, cols):\n",
    "            doc_features_matrix[i][j] = kmp(doc_word_list[i],features[j])*len(features[j])\n",
    "    return doc_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = 'F:\\contest\\subject2_sample\\subject2_sample.txt'\n",
    "params_list,y= decode_file(file_name)\n",
    "doc_word_list = cut_word(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=[\"fclose\",\"script_name\",\"filestools\",\"query\",\"rewriterule\",\"rewritecond\",\"charset=\",\"multipart/form-data\",\"/wwwroot/dwyshw11/wwwroot/home.php\",\"-|\",\"windows-1251\",\"@\",\"/home2/risquemag/public_html/\",\"php_self\",\"charset=utf-8\",\"host_name.\",\"content_mb\",\"--\",\"die\",\"host_name\",\"execut\",\"/wwwroot/dnwcomcn//jiaozhuo.php\",\"rewritebase\",\"domain\",\";\",\"public\",\"netstat\",\"[\",\"posix_getegid\",\"ini_set\",\"{\",\"index.php\",\"substr\",\"&\",\"document_root\",\"doctype\",\"rewriterule\",\"root\",\"tar\",\"strlen\",\"127.0.0.1\",\"!\",\"end\",\"php_uname\",\"ping\",\"foreach\",\"xhtml\",\"-an\",\"http\",\"description\",\"urldecode\",\"enctype\",\"charset=gb2312\",\"opts\",\"delfile\",\"echo\",\"php_config.php\",\"remote_server.\",\".substr\",\"fwrite\",\"set_magic_quotes_runtime\",\"<\",\".php\",\"eval\",\"set_time_limit\",\"execute\",\"gethttppage\",\"ifmodule\",\"filesman\",\"|\",\"meta\",\"loginlogin\",\"print\",\"eval\",\"wscript\",\"http-equiv=\",\"gb2312\",\"xmlns=\",\"echo\",\"get_current_user\",\"array\",\"mkdir\",\"windows\",\"white\",\"google|aol|yahoo|msn|search|bing|seznam|seznam\",\"filesize\",\"function_exists\",\"shell\",\"jstephens\",\"para\",\"fires\",\"path_translated\",\"robots.txt\",\"_p'.'os\",\"melissacalhoun\",\"ie=edge\",\"path_translated\",\"and\",\"response.write\",\"content_mb=gethttppage\",\"^\",\"phpfunc\",\"-\",\"=\",\"-zcvf\",\"begin\",\"content=\",\"net\",\"mod_rewrite.c\",\"content_mb=file_get_contents\",\"buf=\",\"dom\",\"url\",\"}\",\"keywords\",\"mkfile\",\"parameters\",\"title\",\"(\",\"163.com\",\"_server\",\"get\",\"server_name\",\"query_st\",\"transitional\",\".htaccess\",\"view\",\"posix_getpwuid\",\"set\",\"is_dir\",'#',\"wordpress\",\"url=\",\"c1sall\",\"jquery.js\",\"base64_decode\",\"php.exe\",\"remote_server\",\"ifmodule\",\"query_string\",\"http\",\"login\",\"dirname\",\"script_filename\",\"chmod\",\"reg_type\",\"array_map\",\"usr\",\"cmd\",\">\",\"add\",\"host\",\"main\",\"downdb\",\"rename\",\"http_user_agent\",\"systeminfo\",\"base64_\",\"index.php\",\")\",\"prc\",\"html\",\"http\",\"set_time_limit\",\"user\",\"function\",\"/*\",\"str_replace\",\"rewritecond\",\"post\",\"base64_decode\",\"touch\",\"date_default_timezone_set\",\"$\",\"location\",\"utf-8\",\"php_self\",\"request_filename\",\"web.config\",\"fires\",\"text/html\",\"header\",\"edit\",\"rewriterule\",\"posix_geteuid\",\"hunter\",\"header\",\"for\",\"http_host\",\"?\",\"run\",\"isset\",\"range\",\"content-type\",\"visible\",\"base64_decode\",\"fopen\",\"rewritecond\",\".*\",\"display_errors\",\"]\",\"*\",\"wordpress\",\":\",\"head\",\"pwd\",\"eval\",\"buf\",'index.php\",\"edoced_46esab',\"rewriteengine\",\"/bin/sh\",\"trim\",\"fread\",'%','http_referer','x-ua-compatible',\"str_replace\",'eval',\"downfile\"]\n",
    "doc_features_matrix = get_doc_features_matrix(doc_word_list, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (doc_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=doc_features_matrix\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.1, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847511267333\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(max_depth=15,min_samples_split=2,min_samples_leaf=1,max_features=140)\n",
    "clf.fit(X_train,y_train)\n",
    "scores =cross_validation .cross_val_score(clf, X_train, y_train, cv=10, scoring='f1')\n",
    "# #clf.feature_importances_\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.856694\n",
      "best parameters:\n",
      "max_depth: 16\n",
      "min_samples_split: 2\n",
      "min_samples_leaf: 1\n",
      "max_features: 100\n",
      "test score: 0.918919\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(random_state=35)\n",
    "parameters = {'max_depth': [12,13,14,15,16],\n",
    "             'min_samples_split': [2,3,4],  \n",
    "            'min_samples_leaf': [1, 2, 3,4,5] \n",
    "             ,'max_features':[100,]}\n",
    "grid = GridSearchCV(clf, parameters, 'f1', cv=10)\n",
    "grid = grid.fit(X_train, y_train)\n",
    "reg = grid.best_estimator_\n",
    "print('best score: %f'%grid.best_score_)\n",
    "print('best parameters:')\n",
    "for key in parameters.keys():\n",
    "    print('%s: %d'%(key, reg.get_params()[key]))\n",
    "print('test score: %f'%reg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
